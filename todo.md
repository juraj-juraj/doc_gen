# Summary

## What has been done

* Get to know transformers architecture
* Get to know transformers library an nn
* Preprocess dataset
* basic filtering dataset
* fine tuned models
* Parameter efficient low rank training

## What to do next

* Better filter dataset to filter out different styles of docstrings (sphinx, google style, numpydoc, ...)
* experiments on different models
* experinemts on different docstring styles
* run it in better runtime such as ctranslate2
* parse whole python source files and make docstrings to them
* make language server
* make plugin to vscode or neovim 
* Smestral project, obhajoba